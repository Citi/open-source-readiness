---
title: Data Leakage Prevention
tags: 
  - Data Loss (Risk)
  - Placeholder
  - OSPO (Role)
  - Level 3 (OSMM)
sidebar_position: 5
sidebar_label: DLP
---

This article discusses controls that can be put in place to mitigate [Data Leakage Risks](../../Risks/Data-Leakage-Risk), which are almost certainly required for an effective [Open Source Contribution Policy](Contribution-Compliance).

## Existing DLP Software

**See:** [DLP Software](../../Artifacts/DLP-Software) for a discussion on the common ways in which regulated firms use DLP, and how this isn't appropriate for open source contributions.

## Considerations

Financial firms are _technology organisations_. All such organisations need to worry about [Intellectual Property Risk](../../Risks/Data-Leakage-Risk).  IP Leakage can happen anywhere.   Arguably, risks are _greater_ in finance because of the penalties that regulators may apply.

Historically, use of social media / sharing sites has been [prohibited by many firms](../../Artifacts/DLP-Software) to mitigate data leakage.   But you have to balance the data leakage risk against the benefits (outlined above).  Therefore:   can employees use a site like GitHub (where uploading data is commonplace) but have controls in place to mitigate the data-leakage aspect?

## Training

[Training of open source developers](Contribution-Training) within the organisation is an important step:
 
  - Do developers understand the rules?  
  - Can you be explicit about what is and isn't included in a commit?  **For example:**  _non-code contributions_ such as test data might be outside the policy.  It's easier to have a blanket policy that this isn't allowed, since it could be hard to tell the difference between fake and real data.  Test data therefore needs to be generated by the tests as they run instead.
 - A [governance process](Contribution-Compliance) needs to be in place for supervising contributions and observing what leaves the organisation.

## Source Control DLP

Tools can be used to apply a DLP workflow to the GitHub / GitLab source control processes.  

This is a way to push data over the firewall, but with compliance controls.

This can introduce extra friction on contributing open source. 

These tools may help with _evidencing_ (in the form of records) may need to be provided that data hasn't been leaked (according to regulations).

**See:**

 - [GitProxy](https://github.com/finos)
 - [GitHub Enterprise](https://github.com/enterprise)
 
## Personal Machines

Contribution from _outside the firewall_ using personal machines might make sense since the user may not be exposed to confidential information on their personal machines.  This approach could prevent _accidental_ leakage of IP.

## Ephemeral Desktops

Like personal machines, but a vm within your desktop that can access _nothing inside the firewall_.

## GitHub IDs

Opinion varies on the best way to approach this:

### Firm-specific & Personal GitHub IDs

This is where the user has a separate GitHub Id for their own contributions vs. firm ones.  The user's firm email address is associated with one id, whereas their personal address is associated with another.  

 - This allows the firm to perform fine-grained access control on the user, and remove the user from firm-related repos.  It is questionable whether for an open source project the firm should be doing this.  The part of the point of open source is that people can continue contributing despite not working for the firm.
 
 - Arguably, this allows them to perform better tracking of the firm's users across GitHub.

### Single GitHub ID

The user associates their personal _and_ firm email addresses with the same GitHub ID.  

 - From some points of view, _any_ contribution by the user whilst employed at the firm is firm business (see: [ownership of IP](../../Artifacts/CLAs-And-DCOs#Understanding-Copyright)), so there is no point in having a separate ID.  _All contributions should be monitored_.




